Error: Can't open display: (null)
twitter
L1 Log Reg
1
2
3
4
5
6
7
8
9
10
L2 Log Reg
1
2
3
4
5
6
7
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
8
9
10
KNN-3
1
2
3
4
5
6
7
8
9
10
KNN-5
1
2
3
4
5
6
7
8
9
10
KNN-10
1
2
3
4
5
6
7
8
9
10
Linear SVM
1
2
3
4
5
6
7
8
9
10
RBF SVM
1
2
3
4
5
6
7
8
9
10
MLP
1
2
3
4
5
6
7
8
9
10
Naive Bayes
1
2
3
4
5
6
7
8
9
10
QDA
1
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
2
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
3
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
4
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
5
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
6
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
7
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
8
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
9
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
10
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
{'twitter_L1 Log Reg': {'accuracy': 0.8593500212464061, 'auprc': 0.8009483554082628, 'precision': 0.8552693539021863, 'recall': 0.8537643750454611, 'f1': 0.8544775332085986, 'auroc': 0.8591805427342629}, 'twitter_L2 Log Reg': {'accuracy': 0.8592370983584587, 'auprc': 0.8008081461048068, 'precision': 0.8551389306438761, 'recall': 0.8536807799694797, 'f1': 0.8543665738460682, 'auroc': 0.8590735662840672}, 'twitter_KNN-3': {'accuracy': 0.8336420535327778, 'auprc': 0.7996873131799432, 'precision': 0.9273176666466535, 'recall': 0.7120864061944527, 'f1': 0.8054995690368122, 'auroc': 0.8298876730856035}, 'twitter_KNN-5': {'accuracy': 0.8327610396336574, 'auprc': 0.8014743464980588, 'precision': 0.9360046266747067, 'recall': 0.7024081776615808, 'f1': 0.8025059064561317, 'auroc': 0.8287107579201081}, 'twitter_KNN-10': {'accuracy': 0.80662351480578, 'auprc': 0.7799877289492512, 'precision': 0.952539238020071, 'recall': 0.6318254903095274, 'f1': 0.7596625518725191, 'auroc': 0.8011663144950771}, 'twitter_Linear SVM': {'accuracy': 0.8597792976610783, 'auprc': 0.801106086921814, 'precision': 0.8545166537365887, 'recall': 0.8559305161234354, 'f1': 0.8551793300465931, 'auroc': 0.8596763794613989}, 'twitter_RBF SVM': {'accuracy': 0.8928971983222127, 'auprc': 0.8432163743644205, 'precision': 0.8859896301443829, 'recall': 0.8936025837295076, 'f1': 0.8897588779064577, 'auroc': 0.8929256227656989}, 'twitter_MLP': {'accuracy': 0.9048253992492155, 'auprc': 0.8652473288510997, 'precision': 0.9136834956490381, 'recall': 0.8872499108320568, 'f1': 0.9001993323428905, 'auroc': 0.9043701433396283}, 'twitter_Naive Bayes': {'accuracy': 0.8233628911688953, 'auprc': 0.7565994492679723, 'precision': 0.817439996702684, 'recall': 0.8174986624102283, 'f1': 0.8174225905259899, 'auroc': 0.8231735430678961}, 'twitter_QDA': {'accuracy': 0.6460029809274335, 'auprc': 0.5788050176043211, 'precision': 0.6109419051039244, 'recall': 0.7576599226020367, 'f1': 0.6741789786350982, 'auroc': 0.6497543658429235}}
