Error: Can't open display: localhost:19.0
flair-multi-backward
L1 Log Reg
1
2
3
4
5
6
7
8
9
10
{'flair-multi-backward_L1 Log Reg': {'accuracy': 0.8734016021923556, 'auprc': 0.8161298966209556, 'precision': 0.861689210231383, 'recall': 0.8794310882207876, 'f1': 0.8704445805862371, 'auroc': 0.8735914247340284}}
L2 Log Reg
1
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
2
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
3
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
4
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
5
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
6
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
7
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
8
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
9
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
10
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
{'flair-multi-backward_L1 Log Reg': {'accuracy': 0.8734016021923556, 'auprc': 0.8161298966209556, 'precision': 0.861689210231383, 'recall': 0.8794310882207876, 'f1': 0.8704445805862371, 'auroc': 0.8735914247340284}, 'flair-multi-backward_L2 Log Reg': {'accuracy': 0.8670309160472478, 'auprc': 0.8082654372531122, 'precision': 0.8559492580445381, 'recall': 0.8718707846580196, 'f1': 0.8638174911703743, 'auroc': 0.8671635058192798}}
KNN-3
1
2
3
4
5
6
7
8
9
10
{'flair-multi-backward_L1 Log Reg': {'accuracy': 0.8734016021923556, 'auprc': 0.8161298966209556, 'precision': 0.861689210231383, 'recall': 0.8794310882207876, 'f1': 0.8704445805862371, 'auroc': 0.8735914247340284}, 'flair-multi-backward_L2 Log Reg': {'accuracy': 0.8670309160472478, 'auprc': 0.8082654372531122, 'precision': 0.8559492580445381, 'recall': 0.8718707846580196, 'f1': 0.8638174911703743, 'auroc': 0.8671635058192798}, 'flair-multi-backward_KNN-3': {'accuracy': 0.6855376994332215, 'auprc': 0.6435152280755847, 'precision': 0.8747265560621592, 'recall': 0.40847466562642437, 'f1': 0.5568442535175459, 'auroc': 0.6768528227317576}}
KNN-5
1
2
3
4
5
6
7
8
9
10
{'flair-multi-backward_L1 Log Reg': {'accuracy': 0.8734016021923556, 'auprc': 0.8161298966209556, 'precision': 0.861689210231383, 'recall': 0.8794310882207876, 'f1': 0.8704445805862371, 'auroc': 0.8735914247340284}, 'flair-multi-backward_L2 Log Reg': {'accuracy': 0.8670309160472478, 'auprc': 0.8082654372531122, 'precision': 0.8559492580445381, 'recall': 0.8718707846580196, 'f1': 0.8638174911703743, 'auroc': 0.8671635058192798}, 'flair-multi-backward_KNN-3': {'accuracy': 0.6855376994332215, 'auprc': 0.6435152280755847, 'precision': 0.8747265560621592, 'recall': 0.40847466562642437, 'f1': 0.5568442535175459, 'auroc': 0.6768528227317576}, 'flair-multi-backward_KNN-5': {'accuracy': 0.672141557102817, 'auprc': 0.6327484112076633, 'precision': 0.8868169202519507, 'recall': 0.3694751418301009, 'f1': 0.5215215496145257, 'auroc': 0.662658768250847}}
KNN-10
1
2
3
4
5
6
7
8
9
10
{'flair-multi-backward_L1 Log Reg': {'accuracy': 0.8734016021923556, 'auprc': 0.8161298966209556, 'precision': 0.861689210231383, 'recall': 0.8794310882207876, 'f1': 0.8704445805862371, 'auroc': 0.8735914247340284}, 'flair-multi-backward_L2 Log Reg': {'accuracy': 0.8670309160472478, 'auprc': 0.8082654372531122, 'precision': 0.8559492580445381, 'recall': 0.8718707846580196, 'f1': 0.8638174911703743, 'auroc': 0.8671635058192798}, 'flair-multi-backward_KNN-3': {'accuracy': 0.6855376994332215, 'auprc': 0.6435152280755847, 'precision': 0.8747265560621592, 'recall': 0.40847466562642437, 'f1': 0.5568442535175459, 'auroc': 0.6768528227317576}, 'flair-multi-backward_KNN-5': {'accuracy': 0.672141557102817, 'auprc': 0.6327484112076633, 'precision': 0.8868169202519507, 'recall': 0.3694751418301009, 'f1': 0.5215215496145257, 'auroc': 0.662658768250847}, 'flair-multi-backward_KNN-10': {'accuracy': 0.6286999189849986, 'auprc': 0.5935418423072537, 'precision': 0.9067069549961847, 'recall': 0.25924836877717694, 'f1': 0.4031329191507309, 'auroc': 0.6171224923068268}}
Linear SVM
1
2
3
4
5
6
7
8
9
10
{'flair-multi-backward_L1 Log Reg': {'accuracy': 0.8734016021923556, 'auprc': 0.8161298966209556, 'precision': 0.861689210231383, 'recall': 0.8794310882207876, 'f1': 0.8704445805862371, 'auroc': 0.8735914247340284}, 'flair-multi-backward_L2 Log Reg': {'accuracy': 0.8670309160472478, 'auprc': 0.8082654372531122, 'precision': 0.8559492580445381, 'recall': 0.8718707846580196, 'f1': 0.8638174911703743, 'auroc': 0.8671635058192798}, 'flair-multi-backward_KNN-3': {'accuracy': 0.6855376994332215, 'auprc': 0.6435152280755847, 'precision': 0.8747265560621592, 'recall': 0.40847466562642437, 'f1': 0.5568442535175459, 'auroc': 0.6768528227317576}, 'flair-multi-backward_KNN-5': {'accuracy': 0.672141557102817, 'auprc': 0.6327484112076633, 'precision': 0.8868169202519507, 'recall': 0.3694751418301009, 'f1': 0.5215215496145257, 'auroc': 0.662658768250847}, 'flair-multi-backward_KNN-10': {'accuracy': 0.6286999189849986, 'auprc': 0.5935418423072537, 'precision': 0.9067069549961847, 'recall': 0.25924836877717694, 'f1': 0.4031329191507309, 'auroc': 0.6171224923068268}, 'flair-multi-backward_Linear SVM': {'accuracy': 0.8796140401232995, 'auprc': 0.822010632621278, 'precision': 0.8619334357007628, 'recall': 0.8944361246890574, 'f1': 0.8778572188998034, 'auroc': 0.8800778202387842}}
RBF SVM
1
2
3
4
5
6
7
8
9
10
{'flair-multi-backward_L1 Log Reg': {'accuracy': 0.8734016021923556, 'auprc': 0.8161298966209556, 'precision': 0.861689210231383, 'recall': 0.8794310882207876, 'f1': 0.8704445805862371, 'auroc': 0.8735914247340284}, 'flair-multi-backward_L2 Log Reg': {'accuracy': 0.8670309160472478, 'auprc': 0.8082654372531122, 'precision': 0.8559492580445381, 'recall': 0.8718707846580196, 'f1': 0.8638174911703743, 'auroc': 0.8671635058192798}, 'flair-multi-backward_KNN-3': {'accuracy': 0.6855376994332215, 'auprc': 0.6435152280755847, 'precision': 0.8747265560621592, 'recall': 0.40847466562642437, 'f1': 0.5568442535175459, 'auroc': 0.6768528227317576}, 'flair-multi-backward_KNN-5': {'accuracy': 0.672141557102817, 'auprc': 0.6327484112076633, 'precision': 0.8868169202519507, 'recall': 0.3694751418301009, 'f1': 0.5215215496145257, 'auroc': 0.662658768250847}, 'flair-multi-backward_KNN-10': {'accuracy': 0.6286999189849986, 'auprc': 0.5935418423072537, 'precision': 0.9067069549961847, 'recall': 0.25924836877717694, 'f1': 0.4031329191507309, 'auroc': 0.6171224923068268}, 'flair-multi-backward_Linear SVM': {'accuracy': 0.8796140401232995, 'auprc': 0.822010632621278, 'precision': 0.8619334357007628, 'recall': 0.8944361246890574, 'f1': 0.8778572188998034, 'auroc': 0.8800778202387842}, 'flair-multi-backward_RBF SVM': {'accuracy': 0.865313820595816, 'auprc': 0.8020158030664193, 'precision': 0.8420388252787889, 'recall': 0.8882036434055234, 'f1': 0.8644727113312598, 'auroc': 0.8660539795695031}}
MLP
1
2
3
4
5
6
7
8
9
10
{'flair-multi-backward_L1 Log Reg': {'accuracy': 0.8734016021923556, 'auprc': 0.8161298966209556, 'precision': 0.861689210231383, 'recall': 0.8794310882207876, 'f1': 0.8704445805862371, 'auroc': 0.8735914247340284}, 'flair-multi-backward_L2 Log Reg': {'accuracy': 0.8670309160472478, 'auprc': 0.8082654372531122, 'precision': 0.8559492580445381, 'recall': 0.8718707846580196, 'f1': 0.8638174911703743, 'auroc': 0.8671635058192798}, 'flair-multi-backward_KNN-3': {'accuracy': 0.6855376994332215, 'auprc': 0.6435152280755847, 'precision': 0.8747265560621592, 'recall': 0.40847466562642437, 'f1': 0.5568442535175459, 'auroc': 0.6768528227317576}, 'flair-multi-backward_KNN-5': {'accuracy': 0.672141557102817, 'auprc': 0.6327484112076633, 'precision': 0.8868169202519507, 'recall': 0.3694751418301009, 'f1': 0.5215215496145257, 'auroc': 0.662658768250847}, 'flair-multi-backward_KNN-10': {'accuracy': 0.6286999189849986, 'auprc': 0.5935418423072537, 'precision': 0.9067069549961847, 'recall': 0.25924836877717694, 'f1': 0.4031329191507309, 'auroc': 0.6171224923068268}, 'flair-multi-backward_Linear SVM': {'accuracy': 0.8796140401232995, 'auprc': 0.822010632621278, 'precision': 0.8619334357007628, 'recall': 0.8944361246890574, 'f1': 0.8778572188998034, 'auroc': 0.8800778202387842}, 'flair-multi-backward_RBF SVM': {'accuracy': 0.865313820595816, 'auprc': 0.8020158030664193, 'precision': 0.8420388252787889, 'recall': 0.8882036434055234, 'f1': 0.8644727113312598, 'auroc': 0.8660539795695031}, 'flair-multi-backward_MLP': {'accuracy': 0.9124386148302669, 'auprc': 0.8727633851406246, 'precision': 0.9142049923482685, 'recall': 0.9037412442018715, 'f1': 0.9089076145298234, 'auroc': 0.9121703920739114}}
Naive Bayes
1
2
3
4
5
6
7
8
9
10
{'flair-multi-backward_L1 Log Reg': {'accuracy': 0.8734016021923556, 'auprc': 0.8161298966209556, 'precision': 0.861689210231383, 'recall': 0.8794310882207876, 'f1': 0.8704445805862371, 'auroc': 0.8735914247340284}, 'flair-multi-backward_L2 Log Reg': {'accuracy': 0.8670309160472478, 'auprc': 0.8082654372531122, 'precision': 0.8559492580445381, 'recall': 0.8718707846580196, 'f1': 0.8638174911703743, 'auroc': 0.8671635058192798}, 'flair-multi-backward_KNN-3': {'accuracy': 0.6855376994332215, 'auprc': 0.6435152280755847, 'precision': 0.8747265560621592, 'recall': 0.40847466562642437, 'f1': 0.5568442535175459, 'auroc': 0.6768528227317576}, 'flair-multi-backward_KNN-5': {'accuracy': 0.672141557102817, 'auprc': 0.6327484112076633, 'precision': 0.8868169202519507, 'recall': 0.3694751418301009, 'f1': 0.5215215496145257, 'auroc': 0.662658768250847}, 'flair-multi-backward_KNN-10': {'accuracy': 0.6286999189849986, 'auprc': 0.5935418423072537, 'precision': 0.9067069549961847, 'recall': 0.25924836877717694, 'f1': 0.4031329191507309, 'auroc': 0.6171224923068268}, 'flair-multi-backward_Linear SVM': {'accuracy': 0.8796140401232995, 'auprc': 0.822010632621278, 'precision': 0.8619334357007628, 'recall': 0.8944361246890574, 'f1': 0.8778572188998034, 'auroc': 0.8800778202387842}, 'flair-multi-backward_RBF SVM': {'accuracy': 0.865313820595816, 'auprc': 0.8020158030664193, 'precision': 0.8420388252787889, 'recall': 0.8882036434055234, 'f1': 0.8644727113312598, 'auroc': 0.8660539795695031}, 'flair-multi-backward_MLP': {'accuracy': 0.9124386148302669, 'auprc': 0.8727633851406246, 'precision': 0.9142049923482685, 'recall': 0.9037412442018715, 'f1': 0.9089076145298234, 'auroc': 0.9121703920739114}, 'flair-multi-backward_Naive Bayes': {'accuracy': 0.7558845859288263, 'auprc': 0.6891442896766968, 'precision': 0.7840952540925453, 'recall': 0.6837009692964415, 'f1': 0.7303741147755217, 'auroc': 0.7536531082551076}}
QDA
1
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
2
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
3
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
4
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
5
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
6
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
7
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
8
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
9
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
10
/mnt/home/hawki235/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
{'flair-multi-backward_L1 Log Reg': {'accuracy': 0.8734016021923556, 'auprc': 0.8161298966209556, 'precision': 0.861689210231383, 'recall': 0.8794310882207876, 'f1': 0.8704445805862371, 'auroc': 0.8735914247340284}, 'flair-multi-backward_L2 Log Reg': {'accuracy': 0.8670309160472478, 'auprc': 0.8082654372531122, 'precision': 0.8559492580445381, 'recall': 0.8718707846580196, 'f1': 0.8638174911703743, 'auroc': 0.8671635058192798}, 'flair-multi-backward_KNN-3': {'accuracy': 0.6855376994332215, 'auprc': 0.6435152280755847, 'precision': 0.8747265560621592, 'recall': 0.40847466562642437, 'f1': 0.5568442535175459, 'auroc': 0.6768528227317576}, 'flair-multi-backward_KNN-5': {'accuracy': 0.672141557102817, 'auprc': 0.6327484112076633, 'precision': 0.8868169202519507, 'recall': 0.3694751418301009, 'f1': 0.5215215496145257, 'auroc': 0.662658768250847}, 'flair-multi-backward_KNN-10': {'accuracy': 0.6286999189849986, 'auprc': 0.5935418423072537, 'precision': 0.9067069549961847, 'recall': 0.25924836877717694, 'f1': 0.4031329191507309, 'auroc': 0.6171224923068268}, 'flair-multi-backward_Linear SVM': {'accuracy': 0.8796140401232995, 'auprc': 0.822010632621278, 'precision': 0.8619334357007628, 'recall': 0.8944361246890574, 'f1': 0.8778572188998034, 'auroc': 0.8800778202387842}, 'flair-multi-backward_RBF SVM': {'accuracy': 0.865313820595816, 'auprc': 0.8020158030664193, 'precision': 0.8420388252787889, 'recall': 0.8882036434055234, 'f1': 0.8644727113312598, 'auroc': 0.8660539795695031}, 'flair-multi-backward_MLP': {'accuracy': 0.9124386148302669, 'auprc': 0.8727633851406246, 'precision': 0.9142049923482685, 'recall': 0.9037412442018715, 'f1': 0.9089076145298234, 'auroc': 0.9121703920739114}, 'flair-multi-backward_Naive Bayes': {'accuracy': 0.7558845859288263, 'auprc': 0.6891442896766968, 'precision': 0.7840952540925453, 'recall': 0.6837009692964415, 'f1': 0.7303741147755217, 'auroc': 0.7536531082551076}, 'flair-multi-backward_QDA': {'accuracy': 0.546853296500105, 'auprc': 0.507126916884915, 'precision': 0.5492848227627657, 'recall': 0.35830201649035837, 'f1': 0.43210259961745245, 'auroc': 0.5409715488724157}}
